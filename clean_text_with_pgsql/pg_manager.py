from fileinput import filename
import psycopg2
from tqdm import tqdm 
import os
import re

import cleaner_utils as ut

def pg_select(table, where_cond=''):
    try:
        params = ut.config()        
        connection = psycopg2.connect(**params)

        cursor = connection.cursor()
        postgreSQL_select_Query = f'select * from {table}'
        if(where_cond != ''):
            postgreSQL_select_Query += f' where {where_cond}'
        cursor.execute(postgreSQL_select_Query)
        response_records = cursor.fetchall()
        return response_records

    except (Exception, psycopg2.Error) as error:
        print("Error while fetching data from PostgreSQL", error)

    finally:
        # closing database connection.
        if connection:
            cursor.close()
            connection.close()

def pg_run_query(query, with_response=False):
    conn = None
    response = None
    try:
        params = ut.config()
        conn = psycopg2.connect(**params)
        cur = conn.cursor()
        cur.execute(query)
        if(with_response):
            response = cur.fetchall()
        conn.commit()
        cur.close()
        if(with_response):
            return response

    except (Exception, psycopg2.DatabaseError) as error:
        print(error)
    finally:
        if conn is not None:
            conn.close()

    return response

def pg_upsert(table, query_params, values, conflict = ''):
    conn = None
    sql = f"INSERT INTO {table}({','.join(query_params)}) VALUES({','.join(values)})"
    if(conflict != ''):
        sql += f" ON CONFLICT ({conflict}) DO UPDATE SET"
        for param in query_params:
            if(param != conflict):
                sql += f" {param} = EXCLUDED.{param} "
    try:
        params = ut.config()
        conn = psycopg2.connect(**params)
        cur = conn.cursor()
        cur.execute(sql)
        conn.commit()
        cur.close()

    except (Exception, psycopg2.DatabaseError) as error:
        print(error)
    finally:
        if conn is not None:
            conn.close()
        
def create_dict_table(file_name):
    print(f'Creating table public.{file_name}_dict!')

    query = f'''
    DROP TABLE IF EXISTS public.{file_name}_dict CASCADE;
    CREATE TABLE IF NOT EXISTS public.{file_name}_dict (
	id int8 NOT NULL GENERATED BY DEFAULT AS IDENTITY,
	word varchar NOT NULL,
	freq int8 NULL DEFAULT 0,
	word_code int8 NOT NULL,
	CONSTRAINT {file_name}_dict_pk PRIMARY KEY (id),
	CONSTRAINT {file_name}_dict_un UNIQUE (word_code));'''
    pg_run_query(query)

def create_text_table(file_name):
    print(f'Creating table public.{file_name}_text!')

    query = f'''
    DROP TABLE IF EXISTS public.{file_name}_text CASCADE;
    CREATE TABLE IF NOT EXISTS public.{file_name}_text (
	id int8 NOT NULL GENERATED BY DEFAULT AS IDENTITY,
	word_code int8 NOT NULL,
	word_line int8 NOT NULL,
	word_position int8 NOT NULL,
	CONSTRAINT {file_name}_text_pk PRIMARY KEY (id),
	CONSTRAINT {file_name}_text_un UNIQUE (word_line, word_position));'''
    pg_run_query(query)

def check_text_cleaner_tables_exists(in_file):
    file_name = os.path.basename(in_file)
    file_name = file_name.split('.')[0]

    query = f'''SELECT 
    COUNT(table_name)
    FROM 
        information_schema.tables 
    WHERE 
    table_schema ILIKE 'public' AND 
    table_type ILIKE 'BASE TABLE' AND
	(table_name  ILIKE '{file_name}_dict' or table_name  ILIKE '{file_name}_text');'''
    response = pg_run_query(query, True)
    return response[0][0] == 2

def pg_create_dataset_from_file(in_file, file_name):
    create_text_table(file_name)
    create_dict_table(file_name)

    conn = None

    word_dict = {}   
    
    try:
        params = ut.config()
        conn = psycopg2.connect(**params)
        cur = conn.cursor()
        
        # READING FILE FOR DICTIONARY GENARATIONE AND WORD POSITION UPLOADING
        with open(in_file, 'r', encoding="utf8") as in_file:
            text = in_file.readlines()
            print(f'Start elaboration of {len(text)} lines!')

            line_counter = 0
            word_id = 1
            for line in tqdm(text):
                line = line.replace('\n','')
                line = line.replace("'","''")

                line = line.split()
                coded_line = ''          
                for word in line:
                    # POPULATING THE FREQ/WORD/CODE DICTIONARY
                    if word not in word_dict.keys():
                        word_dict[word] = {}
                        word_dict[word]['freq'] = 1
                        word_dict[word]['code'] = word_id
                        word_id += 1
                    else:
                        word_dict[word]['freq'] += 1

                    if(coded_line == ''):
                        coded_line += f"{word_dict[word]['code']}"
                    else:
                        coded_line += f",{word_dict[word]['code']}"

                # WORD POSITION INSERT
                if(coded_line != ''):
                    sql = f"insert into {file_name}_text(word_code, word_line, word_position) select a, {line_counter}, ROW_NUMBER () OVER ( ORDER BY (select null) ) rank_number from unnest(ARRAY[{coded_line}]) a ;"
                    cur.execute(sql)

                line_counter += 1

        # UPLOADING DICTIONAY
        dict_counter = 0
        print(f'Uploading dictionary with {len(word_dict.keys())} keys!\n')
        for key in tqdm(word_dict.keys()):
            sql = f"INSERT INTO {file_name}_dict(word, freq, word_code) VALUES('{key}','{word_dict[key]['freq']}','{word_dict[key]['code']}')"
            cur.execute(sql)
            dict_counter += 1

        print('Cleaning dictionary uppercase!\n')

        clean_inner_uppercase = f'UPDATE {file_name}_dict SET word = LOWER(word) WHERE SUBSTRING(word, 2) != LOWER(SUBSTRING(word, 2))'
        
        cur.execute(clean_inner_uppercase)

        config = ut.config(section='cleaner')

        clean_first_word_uppercase = f'''
        update {file_name}_dict dd1
        set word = LOWER(dd1.word)
        from (
            select dd.word, sum(dd.freq) freq
            from {file_name}_dict dd 
            where dd.word = LOWER(dd.word)
            group by dd.word
        ) dd2
        where SUBSTRING(dd1.word, 1) != LOWER(SUBSTRING(dd1.word, 1))
        and SUBSTRING(dd2.word, 1) = LOWER(SUBSTRING(dd1.word, 1))
        and (dd2.freq) > (dd1.freq * {config['rateo_more_lowercase_init']} );

        update {file_name}_dict dd2
        set word = INITCAP(dd2.word)
        from (
            select dd.word, sum(dd.freq) freq
            from {file_name}_dict dd 
            where dd.word != LOWER(dd.word)
            group by dd.word
        ) dd1
        inner join (
            select dd.word, sum(dd.freq) freq
            from {file_name}_dict dd 
            where dd.word = LOWER(dd.word)
            group by dd.word
        ) dd3 on SUBSTRING(dd3.word, 1) = LOWER(SUBSTRING(dd1.word, 1))
        where SUBSTRING(dd2.word, 1) = LOWER(SUBSTRING(dd2.word, 1))
        and SUBSTRING(dd2.word, 1) = LOWER(SUBSTRING(dd1.word, 1))
        and (dd1.freq) > (dd3.freq * {config['rateo_more_uppercase_init']} );
        '''
        cur.execute(clean_first_word_uppercase)

        print('Unifying Duplicates!\n')

        unify_duplicates_1 = f'''
        update {file_name}_dict dd
        set freq = dd2.freq
        from (
            select word, sum(freq) freq, min(word_code) word_code
            from {file_name}_dict dd2
            group by word
        ) dd2 
        where dd.word_code = dd2.word_code;
        '''
        unify_duplicates_1 = unify_duplicates_1.replace('\n', '')
        unify_duplicates_1 = re.sub(' +', ' ', unify_duplicates_1)       

        unify_duplicates_2 = f'''
        update {file_name}_dict dd
        set freq = 0
        from (
            select word, sum(freq) freq, min(word_code) word_code
            from {file_name}_dict dd2
            group by word
        ) dd2 
        where dd.word_code != dd2.word_code
        and dd.word = dd2.word;
        '''
        unify_duplicates_2 = unify_duplicates_2.replace('\n', '')
        unify_duplicates_2 = re.sub(' +', ' ', unify_duplicates_2)        

        unify_duplicates_3 = f'''
        update {file_name}_text dt
        set word_code = dd2.word_code
        from {file_name}_dict dd
        inner join {file_name}_dict dd2 on (dd.word = dd2.word and dd.word_code != dd2.word_code and dd2.freq != 0)
        where dt.word_code = dd.word_code
        and dd.freq = 0;
        '''
        unify_duplicates_3 = unify_duplicates_3.replace('\n', '')
        unify_duplicates_3 = re.sub(' +', ' ', unify_duplicates_3)        

        unify_duplicates_4 = f'''
        delete from {file_name}_dict dd
        where dd.freq = 0;
        '''
        unify_duplicates_4 = unify_duplicates_4.replace('\n', '')
        unify_duplicates_4 = re.sub(' +', ' ', unify_duplicates_4)

        cur.execute(unify_duplicates_1)
        cur.execute(unify_duplicates_2)
        cur.execute(unify_duplicates_3)
        cur.execute(unify_duplicates_4)

        print('Cleaning Diacritic!\n')

        clean_diacritic = f'''
        update {file_name}_dict dd 
        set word = dd2.word 
        from (
            select distinct on (dd.id) dd.id id, dd2.word word
            from {file_name}_dict dd 
            inner join {file_name}_dict dd2 on SUBSTRING(dd.word, 1, LENGTH(dd.word) - 1) = SUBSTRING(dd2.word, 1, LENGTH(dd2.word) - 1)
            where LENGTH(dd.word) > 1
            and dd.freq > 1
            and(
                (RIGHT(dd2.word, 1) ~ '[àáa]' and RIGHT(dd.word, 1) ~ '[àáa]')
                or (RIGHT(dd2.word, 1) ~ '[èée]' and RIGHT(dd.word, 1) ~ '[èée]')
                or (RIGHT(dd2.word, 1) ~ '[ìíi]' and RIGHT(dd.word, 1) ~ '[ìíi]')
                or (RIGHT(dd2.word, 1) ~ '[òóo]' and RIGHT(dd.word, 1) ~ '[òóo]')
                or (RIGHT(dd2.word, 1) ~ '[ùúu]' and RIGHT(dd.word, 1) ~ '[ùúu]')
            )
            and dd.word != dd2.word
            and (dd.freq * {config['rateo_diacritic']}) < dd2.freq 
            order by dd.id, dd2.freq desc
        ) dd2
        where dd.id = dd2.id
        '''
        clean_diacritic = clean_diacritic.replace('\n', '')
        clean_diacritic = re.sub(' +', ' ', clean_diacritic)

        cur.execute(clean_diacritic)
        cur.execute(unify_duplicates_1)
        cur.execute(unify_duplicates_2)
        cur.execute(unify_duplicates_3)
        cur.execute(unify_duplicates_4)

        conn.commit()
        cur.close()

        print('Upload Committed!')

    except (Exception, psycopg2.DatabaseError) as error:
        print(error)
    finally:
        if conn is not None:
            conn.close()

def get_filtered_data(file_name):
    config = ut.config(section='cleaner')
    query = f'''select string_agg(a.word, ' ')
    from (
        select dspf.word word, dspt.word_line word_line
        from {file_name}_text dspt 
        inner join {file_name}_dict dspf on dspf.word_code = dspt.word_code
        where length(dspf.word) >= {config['min_word_len']}
        and dspf.freq >= {config['min_freq']} 
        and dspf.word ~ {config['regex_filter']}
        order by word_line, word_position asc
    ) as a
    group by a.word_line
    '''
    result = pg_run_query(query, True)
    print('Query done! Now Joining...')
    return result